{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Detailed Run Analysis - Tabular Statistics\n",
    "\n",
    "This notebook provides comprehensive tabular analysis of backtest runs, focusing on trade statistics, position duration, and drawdown metrics.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Trade statistics: win rate, average win/loss, total trades\n",
    "- Position holding duration analysis (in bars)\n",
    "- Maximum drawdown calculations\n",
    "- Comparative tables across multiple runs\n",
    "- No heavy plotting - optimized for quick analysis\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Configure stock symbol\n",
    "2. Scan and filter runs\n",
    "3. Load selected runs\n",
    "4. Review detailed statistics tables\n",
    "\n",
    "Use this notebook when you need precise numbers and comparisons rather than visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add analysis folder to path for imports\n",
    "project_root = Path('/home/pjpr/projects/wee_hedgy_thing/quiescence')\n",
    "analysis_path = project_root / 'analysis'\n",
    "\n",
    "if str(analysis_path) not in sys.path:\n",
    "    sys.path.insert(0, str(analysis_path))\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Import custom utility functions from analysis folder\n",
    "# Force reload if already imported (useful during development)\n",
    "import importlib\n",
    "import utilities\n",
    "importlib.reload(utilities)\n",
    "\n",
    "from utilities import (\n",
    "    scan_backtest_runs, \n",
    "    load_run_data, \n",
    "    create_runs_summary_dataframe, \n",
    "    convert_utc_to_ny,\n",
    "    build_cumulative_pnl_from_positions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set the stock symbol and paths for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "stock_symbol = \"MSFT\"\n",
    "\n",
    "# Project paths\n",
    "STORAGE_ROOT = Path(\"/data/quiescence/\")\n",
    "BACKTEST_ROOT = STORAGE_ROOT / \"backtest\"\n",
    "\n",
    "print(f\"Analyzing stock: {stock_symbol}\")\n",
    "print(f\"Backtest runs root: {BACKTEST_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Scan and Filter Runs\n",
    "\n",
    "Scan all available runs and create a summary DataFrame for filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan all runs for the configured stock (fast - metadata only)\n",
    "runs_metadata = scan_backtest_runs(BACKTEST_ROOT, stock_symbol)\n",
    "\n",
    "# Create summary DataFrame for easy filtering and comparison\n",
    "df_summary = create_runs_summary_dataframe(runs_metadata)\n",
    "\n",
    "print(f\"\\nFound {len(df_summary)} runs for {stock_symbol}\\n\")\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Select Runs to Load\n",
    "\n",
    "Choose which runs to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load ALL runs\n",
    "# runs_data = [load_run_data(run) for run in runs_metadata]\n",
    "\n",
    "# Option 2: Load specific runs by Run number\n",
    "#selected_run_numbers = [11, 19, 23, 34, 42, 43, 47]\n",
    "#runs_data = [load_run_data(runs_metadata[run_num - 1]) for run_num in selected_run_numbers if 0 < run_num <= len(runs_metadata)]\n",
    "\n",
    "# Option 3: Filter using DataFrame conditions\n",
    "# Example: Load runs with specific parameter values\n",
    "#filtered_df = df_summary[\n",
    "#    (df_summary['Entry P Top'].astype(float) >= 0.95) & \n",
    "#    (df_summary['Frequency'] == '1-MINUTE')\n",
    "#]\n",
    "\n",
    "filtered_df = df_summary[(df_summary['Max Pos Bars'] == 9999)]\n",
    "\n",
    "selected_indices = filtered_df['Run'].values - 1\n",
    "runs_data = [load_run_data(runs_metadata[i]) for i in selected_indices]\n",
    "\n",
    "print(f\"\\nLoaded {len(runs_data)} runs:\\n\")\n",
    "print(filtered_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 5. Trade Statistics Summary\n",
    "\n",
    "Calculate comprehensive trading metrics for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRADE STATISTICS CALCULATION ===\n",
    "trade_stats = []\n",
    "\n",
    "for i, run in enumerate(runs_data):\n",
    "    df = run['data']\n",
    "    positions = run['positions_report']\n",
    "    \n",
    "    # Extract bar frequency for display\n",
    "    bar_type = run.get('bar_type', '')\n",
    "    if bar_type:\n",
    "        parts = bar_type.split('-')\n",
    "        frequency = f\"{parts[1]}-{parts[2]}\" if len(parts) >= 3 else 'Unknown'\n",
    "    else:\n",
    "        frequency = 'Unknown'\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_trades = len(positions)\n",
    "    \n",
    "    # Count winning/losing trades\n",
    "    if total_trades > 0 and 'realized_pnl' in positions.columns:\n",
    "        # Clean realized_pnl column\n",
    "        if positions['realized_pnl'].dtype == 'object':\n",
    "            realized_pnl_clean = positions['realized_pnl'].str.replace(' USD', '').astype(float)\n",
    "        else:\n",
    "            realized_pnl_clean = positions['realized_pnl']\n",
    "        \n",
    "        # Calculate win/loss metrics\n",
    "        winning_trades = (realized_pnl_clean > 0).sum()\n",
    "        losing_trades = (realized_pnl_clean < 0).sum()\n",
    "        win_rate = winning_trades / total_trades if total_trades > 0 else 0\n",
    "        \n",
    "        avg_win = realized_pnl_clean[realized_pnl_clean > 0].mean() if winning_trades > 0 else 0\n",
    "        avg_loss = realized_pnl_clean[realized_pnl_clean < 0].mean() if losing_trades > 0 else 0\n",
    "        \n",
    "        # Profit factor (sum of wins / abs(sum of losses))\n",
    "        total_wins = realized_pnl_clean[realized_pnl_clean > 0].sum()\n",
    "        total_losses = abs(realized_pnl_clean[realized_pnl_clean < 0].sum())\n",
    "        profit_factor = total_wins / total_losses if total_losses > 0 else float('inf')\n",
    "        \n",
    "        # Calculate average holding time\n",
    "        if 'duration' in positions.columns:\n",
    "            avg_duration = positions['duration'].mean()\n",
    "        else:\n",
    "            avg_duration = None\n",
    "        \n",
    "        # Final P&L\n",
    "        final_pnl = realized_pnl_clean.sum()\n",
    "    else:\n",
    "        winning_trades = losing_trades = 0\n",
    "        win_rate = avg_win = avg_loss = avg_duration = final_pnl = profit_factor = None\n",
    "    \n",
    "    # Max drawdown calculation from cumulative P&L\n",
    "    if final_pnl is not None:\n",
    "        cumulative_pnl = build_cumulative_pnl_from_positions(positions)\n",
    "        running_max = cumulative_pnl.expanding().max()\n",
    "        drawdown = cumulative_pnl - running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Drawdown percentage (relative to peak)\n",
    "        max_drawdown_pct = (max_drawdown / running_max.max() * 100) if running_max.max() > 0 else 0\n",
    "    else:\n",
    "        max_drawdown = max_drawdown_pct = None\n",
    "    \n",
    "    trade_stats.append({\n",
    "        'Run': i + 1,\n",
    "        'Frequency': frequency,\n",
    "        'Max Pos Bars': run.get('max_position_bars', 'N/A'),\n",
    "        'Total Trades': total_trades,\n",
    "        'Winning': winning_trades,\n",
    "        'Losing': losing_trades,\n",
    "        'Win Rate (%)': f\"{win_rate * 100:.1f}\" if win_rate is not None else 'N/A',\n",
    "        'Avg Win ($)': f\"{avg_win:.2f}\" if avg_win is not None and avg_win > 0 else 'N/A',\n",
    "        'Avg Loss ($)': f\"{avg_loss:.2f}\" if avg_loss is not None and avg_loss < 0 else 'N/A',\n",
    "        'Profit Factor': f\"{profit_factor:.2f}\" if profit_factor is not None and profit_factor != float('inf') else 'N/A',\n",
    "        'Final P&L ($)': f\"{final_pnl:.2f}\" if final_pnl is not None else 'N/A',\n",
    "        'Max DD ($)': f\"{max_drawdown:.2f}\" if max_drawdown is not None else 'N/A',\n",
    "        'Max DD (%)': f\"{max_drawdown_pct:.1f}\" if max_drawdown_pct is not None else 'N/A',\n",
    "        'Avg Duration': f\"{avg_duration}\" if avg_duration is not None else 'N/A',\n",
    "    })\n",
    "\n",
    "# Display as DataFrame\n",
    "df_trade_stats = pd.DataFrame(trade_stats)\n",
    "print(\"\\n\" + \"=\"*130)\n",
    "print(\"TRADE STATISTICS SUMMARY\")\n",
    "print(\"=\"*130 + \"\\n\")\n",
    "print(df_trade_stats.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*130)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 6. Position Holding Duration Analysis\n",
    "\n",
    "Analyze how long positions are held (measured in bars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === POSITION DURATION ANALYSIS ===\n",
    "duration_stats = []\n",
    "\n",
    "for i, run in enumerate(runs_data):\n",
    "    df = run['data']\n",
    "    positions_report = run['positions_report']\n",
    "    \n",
    "    # Extract bar frequency\n",
    "    bar_type = run.get('bar_type', '')\n",
    "    if bar_type:\n",
    "        parts = bar_type.split('-')\n",
    "        frequency = f\"{parts[1]}-{parts[2]}\" if len(parts) >= 3 else 'Unknown'\n",
    "    else:\n",
    "        frequency = 'Unknown'\n",
    "    \n",
    "    # Ensure position column exists\n",
    "    position_col = None\n",
    "    for col in ['current_position_test', 'current_position', 'position']:\n",
    "        if col in df.columns:\n",
    "            position_col = col\n",
    "            break\n",
    "    \n",
    "    if position_col:\n",
    "        # Calculate position changes (when position != previous position)\n",
    "        df['position_change'] = df[position_col].ne(df[position_col].shift())\n",
    "        \n",
    "        # Count bars in each position\n",
    "        df['position_group'] = df['position_change'].cumsum()\n",
    "        position_durations = df.groupby('position_group').size()\n",
    "        \n",
    "        # Exclude flat positions (position = 0) for duration analysis\n",
    "        active_positions = df[df[position_col] != 0].groupby('position_group').size()\n",
    "        \n",
    "        if len(active_positions) > 0:\n",
    "            avg_duration = active_positions.mean()\n",
    "            median_duration = active_positions.median()\n",
    "            max_duration = active_positions.max()\n",
    "            min_duration = active_positions.min()\n",
    "            std_duration = active_positions.std()\n",
    "        else:\n",
    "            avg_duration = median_duration = max_duration = min_duration = std_duration = 0\n",
    "    else:\n",
    "        avg_duration = median_duration = max_duration = min_duration = std_duration = None\n",
    "    \n",
    "    duration_stats.append({\n",
    "        'Run': i + 1,\n",
    "        'Frequency': frequency,\n",
    "        'Max Pos Bars': run.get('max_position_bars', 'N/A'),\n",
    "        'Avg Duration (bars)': f\"{avg_duration:.1f}\" if avg_duration is not None else 'N/A',\n",
    "        'Median Duration (bars)': f\"{median_duration:.0f}\" if median_duration is not None else 'N/A',\n",
    "        'Std Duration (bars)': f\"{std_duration:.1f}\" if std_duration is not None else 'N/A',\n",
    "        'Max Duration (bars)': f\"{max_duration}\" if max_duration is not None else 'N/A',\n",
    "        'Min Duration (bars)': f\"{min_duration}\" if min_duration is not None else 'N/A',\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_duration_stats = pd.DataFrame(duration_stats)\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"POSITION HOLDING DURATION ANALYSIS\")\n",
    "print(\"=\"*110 + \"\\n\")\n",
    "print(df_duration_stats.to_string(index=False))\n",
    "print(\"\\nNote: Duration measured in number of bars, not time units.\")\n",
    "print(\"=\"*110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 7. Drawdown Analysis Table\n",
    "\n",
    "Detailed drawdown metrics for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DRAWDOWN ANALYSIS ===\n",
    "drawdown_stats = []\n",
    "\n",
    "for i, run in enumerate(runs_data):\n",
    "    df = run['data']\n",
    "    positions = run['positions_report']\n",
    "    \n",
    "    # Extract bar frequency\n",
    "    bar_type = run.get('bar_type', '')\n",
    "    if bar_type:\n",
    "        parts = bar_type.split('-')\n",
    "        frequency = f\"{parts[1]}-{parts[2]}\" if len(parts) >= 3 else 'Unknown'\n",
    "    else:\n",
    "        frequency = 'Unknown'\n",
    "    \n",
    "    # Build cumulative P&L\n",
    "    pnl = build_cumulative_pnl_from_positions(positions)\n",
    "    \n",
    "    if len(pnl) > 0:\n",
    "        # Calculate running maximum and drawdown\n",
    "        running_max = pnl.expanding().max()\n",
    "        drawdown = pnl - running_max\n",
    "        \n",
    "        # Find maximum drawdown\n",
    "        max_dd = drawdown.min()\n",
    "        max_dd_idx = drawdown.idxmin()\n",
    "        \n",
    "        # Find the peak before max drawdown\n",
    "        peak_before_dd = running_max.loc[:max_dd_idx].idxmax()\n",
    "        \n",
    "        # Calculate drawdown duration (number of bars in drawdown)\n",
    "        dd_duration = len(drawdown[peak_before_dd:max_dd_idx])\n",
    "        \n",
    "        # Calculate recovery (if recovered)\n",
    "        after_dd = pnl[max_dd_idx:]\n",
    "        peak_value = running_max.loc[max_dd_idx]\n",
    "        recovered = (after_dd >= peak_value).any() if len(after_dd) > 0 else False\n",
    "        \n",
    "        if recovered:\n",
    "            recovery_idx = after_dd[after_dd >= peak_value].index[0]\n",
    "            recovery_duration = len(pnl[max_dd_idx:recovery_idx])\n",
    "        else:\n",
    "            recovery_duration = None\n",
    "        \n",
    "        # Drawdown percentage\n",
    "        max_dd_pct = (max_dd / peak_value * 100) if peak_value > 0 else 0\n",
    "        \n",
    "        # Final P&L\n",
    "        final_pnl = pnl.iloc[-1]\n",
    "    else:\n",
    "        max_dd = max_dd_pct = dd_duration = recovery_duration = final_pnl = None\n",
    "    \n",
    "    drawdown_stats.append({\n",
    "        'Run': i + 1,\n",
    "        'Frequency': frequency,\n",
    "        'Max Pos Bars': run.get('max_position_bars', 'N/A'),\n",
    "        'Final P&L ($)': f\"{final_pnl:.2f}\" if final_pnl is not None else 'N/A',\n",
    "        'Max Drawdown ($)': f\"{max_dd:.2f}\" if max_dd is not None else 'N/A',\n",
    "        'Max DD (%)': f\"{max_dd_pct:.1f}\" if max_dd_pct is not None else 'N/A',\n",
    "        'DD Duration (bars)': f\"{dd_duration}\" if dd_duration is not None else 'N/A',\n",
    "        'Recovery Duration (bars)': f\"{recovery_duration}\" if recovery_duration is not None else 'Not Recovered',\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_drawdown_stats = pd.DataFrame(drawdown_stats)\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"DRAWDOWN ANALYSIS\")\n",
    "print(\"=\"*110 + \"\\n\")\n",
    "print(df_drawdown_stats.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 8. Combined Summary Report\n",
    "\n",
    "All key metrics in one comprehensive table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all statistics into one comprehensive report\n",
    "combined_stats = []\n",
    "\n",
    "for i in range(len(runs_data)):\n",
    "    # Get stats from each analysis\n",
    "    trade_stat = trade_stats[i] if i < len(trade_stats) else {}\n",
    "    duration_stat = duration_stats[i] if i < len(duration_stats) else {}\n",
    "    drawdown_stat = drawdown_stats[i] if i < len(drawdown_stats) else {}\n",
    "    \n",
    "    combined_stats.append({\n",
    "        'Run': i + 1,\n",
    "        'Frequency': trade_stat.get('Frequency', 'N/A'),\n",
    "        'Max Pos Bars': trade_stat.get('Max Pos Bars', 'N/A'),\n",
    "        'Total Trades': trade_stat.get('Total Trades', 'N/A'),\n",
    "        'Win Rate': trade_stat.get('Win Rate (%)', 'N/A'),\n",
    "        'Profit Factor': trade_stat.get('Profit Factor', 'N/A'),\n",
    "        'Final P&L': trade_stat.get('Final P&L ($)', 'N/A'),\n",
    "        'Max DD': drawdown_stat.get('Max Drawdown ($)', 'N/A'),\n",
    "        'Max DD %': drawdown_stat.get('Max DD (%)', 'N/A'),\n",
    "        'Avg Duration': duration_stat.get('Avg Duration (bars)', 'N/A'),\n",
    "    })\n",
    "\n",
    "df_combined = pd.DataFrame(combined_stats)\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"COMBINED SUMMARY REPORT\")\n",
    "print(\"=\"*110 + \"\\n\")\n",
    "print(df_combined.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "\n",
    "# Identify top performers\n",
    "if len(df_combined) > 0:\n",
    "    print(\"\\nüèÜ TOP PERFORMERS:\\n\")\n",
    "    \n",
    "    # Best final P&L\n",
    "    df_combined['Final P&L (numeric)'] = df_combined['Final P&L'].str.replace('$', '').str.replace(',', '').astype(float, errors='ignore')\n",
    "    best_pnl_idx = df_combined['Final P&L (numeric)'].idxmax()\n",
    "    print(f\"Highest P&L: Run {df_combined.loc[best_pnl_idx, 'Run']} with ${df_combined.loc[best_pnl_idx, 'Final P&L']}\")\n",
    "    \n",
    "    # Best win rate\n",
    "    df_combined['Win Rate (numeric)'] = df_combined['Win Rate'].str.replace('%', '').astype(float, errors='ignore')\n",
    "    best_wr_idx = df_combined['Win Rate (numeric)'].idxmax()\n",
    "    print(f\"Highest Win Rate: Run {df_combined.loc[best_wr_idx, 'Run']} with {df_combined.loc[best_wr_idx, 'Win Rate']}\")\n",
    "    \n",
    "    # Best profit factor\n",
    "    df_combined['Profit Factor (numeric)'] = df_combined['Profit Factor'].astype(float, errors='ignore')\n",
    "    best_pf_idx = df_combined['Profit Factor (numeric)'].idxmax()\n",
    "    print(f\"Best Profit Factor: Run {df_combined.loc[best_pf_idx, 'Run']} with {df_combined.loc[best_pf_idx, 'Profit Factor']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quiescence (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
