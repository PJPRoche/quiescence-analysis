{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# P&L vs Duration Correlation Analysis\n",
    "\n",
    "This notebook analyzes the relationship between position holding duration and trade profitability to identify if the strategy benefits from quick exits or longer holds.\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "- Do longer-held positions tend to be more or less profitable?\n",
    "- Is there an optimal holding time for maximizing returns?\n",
    "- Does the correlation differ across different run configurations?\n",
    "- Should the strategy implement time-based exits or stop-losses?\n",
    "\n",
    "## Features\n",
    "\n",
    "- Scatter plots showing P&L vs duration for each trade\n",
    "- Correlation coefficients for each run\n",
    "- Statistical analysis of duration vs profitability\n",
    "- Comparative insights across multiple configurations\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Configure stock symbol\n",
    "2. Scan and filter runs\n",
    "3. Load selected runs\n",
    "4. Analyze P&L vs duration relationships\n",
    "\n",
    "Use this notebook to understand if your strategy suffers from holding losers too long or cutting winners too early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add analysis folder to path for imports\n",
    "project_root = Path('/home/pjpr/projects/wee_hedgy_thing/quiescence')\n",
    "analysis_path = project_root / 'analysis'\n",
    "\n",
    "if str(analysis_path) not in sys.path:\n",
    "    sys.path.insert(0, str(analysis_path))\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Import custom utility functions from analysis folder\n",
    "from utilities import (\n",
    "    scan_backtest_runs, \n",
    "    load_run_data, \n",
    "    create_runs_summary_dataframe, \n",
    "    convert_utc_to_ny,\n",
    "    build_cumulative_pnl_from_positions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set the stock symbol and paths for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "stock_symbol = \"MSFT\"\n",
    "\n",
    "# Project paths\n",
    "STORAGE_ROOT = Path(\"/data/quiescence/\")\n",
    "BACKTEST_ROOT = STORAGE_ROOT / \"backtest\"\n",
    "\n",
    "print(f\"Analyzing stock: {stock_symbol}\")\n",
    "print(f\"Backtest runs root: {BACKTEST_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Scan and Filter Runs\n",
    "\n",
    "Scan all available runs and create a summary DataFrame for filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan all runs for the configured stock (fast - metadata only)\n",
    "runs_metadata = scan_backtest_runs(BACKTEST_ROOT, stock_symbol)\n",
    "\n",
    "# Create summary DataFrame for easy filtering and comparison\n",
    "df_summary = create_runs_summary_dataframe(runs_metadata)\n",
    "\n",
    "print(f\"\\nFound {len(df_summary)} runs for {stock_symbol}\\n\")\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Select Runs to Load\n",
    "\n",
    "Choose which runs to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load ALL runs\n",
    "# runs_data = [load_run_data(run) for run in runs_metadata]\n",
    "\n",
    "# Option 2: Load specific runs by Run number\n",
    "#selected_run_numbers = [11, 19, 23, 34, 42, 43, 47]\n",
    "#runs_data = [load_run_data(runs_metadata[run_num - 1]) for run_num in selected_run_numbers if 0 < run_num <= len(runs_metadata)]\n",
    "\n",
    "# Option 3: Filter using DataFrame conditions\n",
    "# Example: Load runs with specific parameter values\n",
    "#filtered_df = df_summary[\n",
    "#    (df_summary['Entry P Top'].astype(float) >= 0.95) & \n",
    "#    (df_summary['Frequency'] == '1-MINUTE')\n",
    "#]\n",
    "\n",
    "filtered_df = df_summary[(df_summary['Max Pos Bars'] == 9999)]\n",
    "\n",
    "selected_indices = filtered_df['Run'].values - 1\n",
    "runs_data = [load_run_data(runs_metadata[i]) for i in selected_indices]\n",
    "\n",
    "print(f\"\\nLoaded {len(runs_data)} runs:\\n\")\n",
    "print(filtered_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Helper Function: Extract Position Data\n",
    "\n",
    "This function formats position data from the positions report for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_positions_from_report(positions_report, debug=False):\n",
    "    \"\"\"\n",
    "    Extract and format position data from positions report for analysis.\n",
    "    \n",
    "    Args:\n",
    "        positions_report: DataFrame with positions data including duration, realized_pnl, timestamps\n",
    "        debug: If True, print debugging information\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: entry_ts, exit_ts, duration_minutes, trade_pnl\n",
    "    \"\"\"\n",
    "    if positions_report.empty or 'realized_pnl' not in positions_report.columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Columns available: {positions_report.columns.tolist()}\")\n",
    "        print(f\"Row count: {len(positions_report)}\")\n",
    "    \n",
    "    # Create formatted dataframe\n",
    "    df_positions = pd.DataFrame()\n",
    "    \n",
    "    # Calculate duration in minutes\n",
    "    # First check for duration_ns (duration in nanoseconds)\n",
    "    if 'duration_ns' in positions_report.columns:\n",
    "        duration_col = positions_report['duration_ns']\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Using duration_ns column\")\n",
    "            print(f\"Duration_ns dtype: {duration_col.dtype}\")\n",
    "            print(f\"Duration_ns sample values: {duration_col.head()}\")\n",
    "        \n",
    "        # Convert nanoseconds to minutes\n",
    "        df_positions['duration_minutes'] = pd.to_numeric(duration_col, errors='coerce') / 1e9 / 60\n",
    "        \n",
    "    # Check for duration column (legacy support)\n",
    "    elif 'duration' in positions_report.columns:\n",
    "        duration_col = positions_report['duration']\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Using duration column\")\n",
    "            print(f\"Duration column dtype: {duration_col.dtype}\")\n",
    "        \n",
    "        if pd.api.types.is_timedelta64_dtype(duration_col):\n",
    "            df_positions['duration_minutes'] = duration_col.dt.total_seconds() / 60\n",
    "        elif pd.api.types.is_numeric_dtype(duration_col):\n",
    "            # Assume nanoseconds\n",
    "            df_positions['duration_minutes'] = duration_col / 1e9 / 60\n",
    "        else:\n",
    "            # Try to parse as timedelta string or numeric\n",
    "            try:\n",
    "                df_positions['duration_minutes'] = pd.to_timedelta(duration_col).dt.total_seconds() / 60\n",
    "            except:\n",
    "                df_positions['duration_minutes'] = pd.to_numeric(duration_col, errors='coerce') / 1e9 / 60\n",
    "    \n",
    "    # Fallback: calculate from timestamps\n",
    "    elif 'ts_opened' in positions_report.columns and 'ts_closed' in positions_report.columns:\n",
    "        if debug:\n",
    "            print(\"Calculating duration from ts_opened and ts_closed\")\n",
    "        \n",
    "        ts_opened = pd.to_numeric(positions_report['ts_opened'], errors='coerce')\n",
    "        ts_closed = pd.to_numeric(positions_report['ts_closed'], errors='coerce')\n",
    "        duration_ns = ts_closed - ts_opened\n",
    "        df_positions['duration_minutes'] = duration_ns / 1e9 / 60\n",
    "    \n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"Warning: No duration column or timestamps available\")\n",
    "        df_positions['duration_minutes'] = 0\n",
    "    \n",
    "    # Extract P&L - handle both string format (\"65.62 USD\") and numeric\n",
    "    pnl_col = positions_report['realized_pnl']\n",
    "    if pnl_col.dtype == 'object':\n",
    "        df_positions['trade_pnl'] = pnl_col.str.replace(' USD', '').astype(float)\n",
    "    else:\n",
    "        df_positions['trade_pnl'] = pnl_col\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Rows before dropna: {len(df_positions)}\")\n",
    "        print(f\"Duration NaN count: {df_positions['duration_minutes'].isna().sum()}\")\n",
    "        print(f\"P&L NaN count: {df_positions['trade_pnl'].isna().sum()}\")\n",
    "        if len(df_positions) > 0:\n",
    "            print(f\"Duration sample values: {df_positions['duration_minutes'].head()}\")\n",
    "    \n",
    "    # Drop rows with missing data\n",
    "    df_positions = df_positions.dropna(subset=['duration_minutes', 'trade_pnl'])\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Rows after dropna: {len(df_positions)}\")\n",
    "    \n",
    "    return df_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. P&L vs Duration Correlation Visualization\n",
    "\n",
    "Create scatter plots showing the relationship between position duration and profitability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use matplotlib colors for distinguishing runs\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "\n",
    "# Configuration for visualization\n",
    "MAX_DURATION_MINUTES = 50  # Maximum x-axis limit (5 hours)\n",
    "\n",
    "correlation_stats = []\n",
    "plot_data = []  # Store data for plotting\n",
    "\n",
    "# First pass: collect all data and statistics\n",
    "for i, run in enumerate(runs_data):\n",
    "    positions_report = run['positions_report']\n",
    "    \n",
    "    # Extract bar frequency for labeling\n",
    "    bar_type = run.get('bar_type', '')\n",
    "    if bar_type:\n",
    "        parts = bar_type.split('-')\n",
    "        frequency = f\"{parts[1]}-{parts[2]}\" if len(parts) >= 3 else 'Unknown'\n",
    "    else:\n",
    "        frequency = 'Unknown'\n",
    "    \n",
    "    # Check if we have positions data\n",
    "    if positions_report.empty or 'realized_pnl' not in positions_report.columns:\n",
    "        print(f\"Warning: Run {i+1} missing positions data or 'realized_pnl' column\")\n",
    "        continue\n",
    "    \n",
    "    # Extract positions from report (enable debug for first run)\n",
    "    df_positions = extract_positions_from_report(positions_report, debug=(i==0))\n",
    "    \n",
    "    if len(df_positions) == 0:\n",
    "        print(f\"Warning: Run {i+1} has no positions extracted from report\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = df_positions['duration_minutes'].corr(df_positions['trade_pnl'])\n",
    "    \n",
    "    # Get trading hours for label\n",
    "    trading_hours = run.get(\"trading_hours\", {})\n",
    "    if isinstance(trading_hours, dict):\n",
    "        start_time = trading_hours.get(\"start\", \"N/A\")\n",
    "        if hasattr(start_time, 'strftime'):\n",
    "            start_time = start_time.strftime('%H:%M')\n",
    "    else:\n",
    "        start_time = run.get(\"trading_start_time\", \"N/A\")\n",
    "        if hasattr(start_time, 'strftime'):\n",
    "            start_time = start_time.strftime('%H:%M')\n",
    "    \n",
    "    max_pos_bars = run.get('max_position_bars', 'N/A')\n",
    "    \n",
    "    # Store plot data\n",
    "    plot_data.append({\n",
    "        'run_num': i + 1,\n",
    "        'df': df_positions,\n",
    "        'frequency': frequency,\n",
    "        'max_pos_bars': max_pos_bars,\n",
    "        'correlation': correlation,\n",
    "        'color': colors[i % len(colors)]\n",
    "    })\n",
    "    \n",
    "    # Store correlation statistics\n",
    "    correlation_stats.append({\n",
    "        'Run': i + 1,\n",
    "        'Frequency': frequency,\n",
    "        'Max Pos Bars': max_pos_bars,\n",
    "        'Start Time': start_time,\n",
    "        'Trades': len(df_positions),\n",
    "        'Correlation': correlation,\n",
    "        'Interpretation': 'Negative' if correlation < 0 else 'Positive',\n",
    "        'Strength': 'Strong' if abs(correlation) > 0.5 else 'Moderate' if abs(correlation) > 0.3 else 'Weak'\n",
    "    })\n",
    "\n",
    "# Second pass: create subplots\n",
    "n_runs = len(plot_data)\n",
    "if n_runs > 0:\n",
    "    # Calculate grid dimensions (prefer wider layouts)\n",
    "    n_cols = min(3, n_runs)  # Maximum 3 columns\n",
    "    n_rows = (n_runs + n_cols - 1) // n_cols  # Ceiling division\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows))\n",
    "    \n",
    "    # Handle case where axes might not be a 2D array\n",
    "    if n_runs == 1:\n",
    "        axes = [[axes]]\n",
    "    elif n_rows == 1:\n",
    "        axes = [axes]\n",
    "    elif n_cols == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "    \n",
    "    # Plot each run\n",
    "    for idx, data in enumerate(plot_data):\n",
    "        row = idx // n_cols\n",
    "        col = idx % n_cols\n",
    "        ax = axes[row][col]\n",
    "        \n",
    "        df = data['df']\n",
    "        \n",
    "        # Create scatter plot\n",
    "        ax.scatter(\n",
    "            df['duration_minutes'],\n",
    "            df['trade_pnl'],\n",
    "            c=data['color'],\n",
    "            s=20,\n",
    "            alpha=0.5,\n",
    "            edgecolors='darkgray',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        \n",
    "        # Add horizontal line at y=0\n",
    "        ax.axhline(y=0, linestyle='--', color='gray', linewidth=1, alpha=0.7)\n",
    "        \n",
    "        # Set title and labels\n",
    "        title = f\"Run {data['run_num']}: {data['frequency']}\\n(Max:{data['max_pos_bars']}) - Corr: {data['correlation']:.3f}\"\n",
    "        ax.set_title(title, fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Duration (minutes)', fontsize=9)\n",
    "        ax.set_ylabel('P&L ($)', fontsize=9)\n",
    "        \n",
    "        # Set x-axis limit\n",
    "        ax.set_xlim(0, MAX_DURATION_MINUTES)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for idx in range(n_runs, n_rows * n_cols):\n",
    "        row = idx // n_cols\n",
    "        col = idx % n_cols\n",
    "        axes[row][col].set_visible(False)\n",
    "    \n",
    "    # Add overall title\n",
    "    fig.suptitle(f'{stock_symbol} - Trade P&L vs Duration Correlation', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available to plot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Correlation Statistics Table\n",
    "\n",
    "Display correlation coefficients and interpretation for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display correlation statistics table\n",
    "if correlation_stats:\n",
    "    df_correlation = pd.DataFrame(correlation_stats)\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"P&L vs DURATION CORRELATION ANALYSIS - {stock_symbol}\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    print(df_correlation.to_string(index=False))\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    \n",
    "    # Summary insights\n",
    "    negative_corr_count = sum(1 for stat in correlation_stats if stat['Correlation'] < 0)\n",
    "    total_runs = len(correlation_stats)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š SUMMARY INSIGHTS:\\n\")\n",
    "    print(f\"  - {negative_corr_count}/{total_runs} runs show negative correlation (longer = less profitable)\")\n",
    "    print(f\"  - {total_runs - negative_corr_count}/{total_runs} runs show positive correlation (longer = more profitable)\")\n",
    "    \n",
    "    avg_correlation = sum(stat['Correlation'] for stat in correlation_stats) / total_runs\n",
    "    print(f\"  - Average correlation across all runs: {avg_correlation:.3f}\")\n",
    "    \n",
    "    if avg_correlation < -0.3:\n",
    "        print(f\"\\n  âš ï¸  STRONG NEGATIVE PATTERN: Longer trades consistently lose money!\")\n",
    "        print(f\"      ðŸ’¡ RECOMMENDATION: Implement tighter stop-losses or time-based exits.\")\n",
    "        print(f\"      ðŸ’¡ Consider reducing max_position_bars parameter.\")\n",
    "    elif avg_correlation < 0:\n",
    "        print(f\"\\n  âš ï¸  WEAK NEGATIVE PATTERN: Slight tendency for longer trades to underperform.\")\n",
    "        print(f\"      ðŸ’¡ RECOMMENDATION: Review and potentially tighten exit conditions.\")\n",
    "    elif avg_correlation > 0.3:\n",
    "        print(f\"\\n  âœ… POSITIVE PATTERN: Longer trades tend to be more profitable.\")\n",
    "        print(f\"      ðŸ’¡ RECOMMENDATION: Strategy benefits from patience and letting winners run.\")\n",
    "        print(f\"      ðŸ’¡ Consider allowing more time before forced exits.\")\n",
    "    else:\n",
    "        print(f\"\\n  â„¹ï¸  WEAK/NO CORRELATION: Position duration has minimal impact on profitability.\")\n",
    "        print(f\"      ðŸ’¡ RECOMMENDATION: Focus on entry/exit conditions rather than holding time.\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\\n\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No correlation data available - check that runs have valid orders data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 7. Duration Distribution Analysis\n",
    "\n",
    "Analyze the distribution of position durations to understand typical holding times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze duration distributions for each run\n",
    "duration_dist_stats = []\n",
    "\n",
    "for i, run in enumerate(runs_data):\n",
    "    positions_report = run['positions_report']\n",
    "    \n",
    "    # Extract bar frequency\n",
    "    bar_type = run.get('bar_type', '')\n",
    "    if bar_type:\n",
    "        parts = bar_type.split('-')\n",
    "        frequency = f\"{parts[1]}-{parts[2]}\" if len(parts) >= 3 else 'Unknown'\n",
    "    else:\n",
    "        frequency = 'Unknown'\n",
    "    \n",
    "    # Check if we have positions data\n",
    "    if positions_report.empty or 'realized_pnl' not in positions_report.columns:\n",
    "        continue\n",
    "    \n",
    "    # Extract positions from report\n",
    "    df_positions = extract_positions_from_report(positions_report)\n",
    "    \n",
    "    if len(df_positions) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate duration statistics\n",
    "    durations = df_positions['duration_minutes']\n",
    "    \n",
    "    duration_dist_stats.append({\n",
    "        'Run': i + 1,\n",
    "        'Frequency': frequency,\n",
    "        'Max Pos Bars': run.get('max_position_bars', 'N/A'),\n",
    "        'Trades': len(df_positions),\n",
    "        'Avg Duration (min)': f\"{durations.mean():.1f}\",\n",
    "        'Median Duration (min)': f\"{durations.median():.1f}\",\n",
    "        'Std Duration (min)': f\"{durations.std():.1f}\",\n",
    "        'Min Duration (min)': f\"{durations.min():.1f}\",\n",
    "        'Max Duration (min)': f\"{durations.max():.1f}\",\n",
    "        '25th Percentile (min)': f\"{durations.quantile(0.25):.1f}\",\n",
    "        '75th Percentile (min)': f\"{durations.quantile(0.75):.1f}\",\n",
    "    })\n",
    "\n",
    "# Display duration distribution statistics\n",
    "if duration_dist_stats:\n",
    "    df_duration_dist = pd.DataFrame(duration_dist_stats)\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"POSITION DURATION DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*120 + \"\\n\")\n",
    "    print(df_duration_dist.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 8. Profitability by Duration Buckets\n",
    "\n",
    "Analyze profitability across different duration buckets to find optimal holding times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze profitability by duration buckets\n",
    "for i, run in enumerate(runs_data):\n",
    "    positions_report = run['positions_report']\n",
    "    \n",
    "    # Extract bar frequency\n",
    "    bar_type = run.get('bar_type', '')\n",
    "    if bar_type:\n",
    "        parts = bar_type.split('-')\n",
    "        frequency = f\"{parts[1]}-{parts[2]}\" if len(parts) >= 3 else 'Unknown'\n",
    "    else:\n",
    "        frequency = 'Unknown'\n",
    "    \n",
    "    # Check if we have positions data\n",
    "    if positions_report.empty or 'realized_pnl' not in positions_report.columns:\n",
    "        continue\n",
    "    \n",
    "    # Extract positions from report\n",
    "    df_positions = extract_positions_from_report(positions_report)\n",
    "    \n",
    "    if len(df_positions) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Create duration buckets\n",
    "    df_positions['duration_bucket'] = pd.cut(\n",
    "        df_positions['duration_minutes'],\n",
    "        bins=[0, 15, 30, 60, 120, 240, float('inf')],\n",
    "        labels=['0-15min', '15-30min', '30-60min', '1-2hr', '2-4hr', '4hr+']\n",
    "    )\n",
    "    \n",
    "    # Calculate statistics for each bucket\n",
    "    bucket_stats = df_positions.groupby('duration_bucket').agg({\n",
    "        'trade_pnl': ['count', 'mean', 'sum', lambda x: (x > 0).sum()],\n",
    "        'duration_minutes': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    bucket_stats.columns = ['Trades', 'Avg P&L', 'Total P&L', 'Winners', 'Avg Duration']\n",
    "    bucket_stats['Win Rate (%)'] = (bucket_stats['Winners'] / bucket_stats['Trades'] * 100).round(1)\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Run {i+1}: {run.get('ticker', stock_symbol)} | {frequency} | Max Pos Bars: {run.get('max_position_bars', 'N/A')}\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    print(bucket_stats.to_string())\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    \n",
    "    # Identify best bucket\n",
    "    best_bucket = bucket_stats['Avg P&L'].idxmax()\n",
    "    print(f\"\\nðŸ’° Most profitable duration bucket: {best_bucket} (Avg P&L: ${bucket_stats.loc[best_bucket, 'Avg P&L']:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quiescence (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
